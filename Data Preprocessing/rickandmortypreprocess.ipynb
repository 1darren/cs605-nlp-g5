{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import chardet\n",
    "\n",
    "def preprocess_rick_and_morty_script(input_file, output_file):\n",
    "    # Detect the encoding of the input file\n",
    "    with open(input_file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    encoding = result['encoding']\n",
    "\n",
    "    # Load the CSV file with the detected encoding\n",
    "    data = pd.read_csv(input_file, header=None, names=['season', 'episode', 'text'], encoding=encoding)\n",
    "\n",
    "    # Initialize a list to store the processed rows\n",
    "    processed_rows = []\n",
    "\n",
    "    # Group by season and episode\n",
    "    grouped = data.groupby(['season', 'episode'])\n",
    "\n",
    "    for (season, episode), group in grouped:\n",
    "        # 1. Delete any string that is in square brackets or brackets (together with the square brackets or brackets)\n",
    "        group['text'] = group['text'].apply(lambda x: re.sub(r'\\[.*?\\]|\\(.*?\\)', '', x))\n",
    "\n",
    "        # 2. Delete any rows that are blank\n",
    "        group = group[group['text'].str.strip() != '']\n",
    "\n",
    "        # 3. If any row does not contain a colon, append its content to the previous row split with a space and delete the current row\n",
    "        processed_data = []\n",
    "        buffer = \"\"\n",
    "\n",
    "        for row in group['text']:\n",
    "            if ':' in row:\n",
    "                if buffer:\n",
    "                    processed_data.append(buffer.strip())\n",
    "                    buffer = \"\"\n",
    "                processed_data.append(row.strip())\n",
    "            else:\n",
    "                buffer += \" \" + row.strip()\n",
    "\n",
    "        if buffer:\n",
    "            processed_data.append(buffer.strip())\n",
    "\n",
    "        # 4. Split the text into character name and dialogue, and remove any blanks at the start of the dialogue string\n",
    "        for row in processed_data:\n",
    "            split_row = row.split(':', 1)\n",
    "            if len(split_row) == 2:\n",
    "                character, dialogue = split_row\n",
    "                processed_rows.append([season, episode, character.strip(), dialogue.strip()])\n",
    "\n",
    "    # Convert the list back to a DataFrame\n",
    "    processed_data_df = pd.DataFrame(processed_rows, columns=['season', 'episode', 'character', 'dialogue'])\n",
    "\n",
    "    # Write the processed data into a new CSV file\n",
    "    processed_data_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "# Usage\n",
    "input_file = 'RickandMortySeason1-3.csv'\n",
    "output_file = 'Processed_RickandMortySeason1-3.csv'\n",
    "preprocess_rick_and_morty_script(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved as RickDialogues.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Processed_RickandMortySeason1-7.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Process the DataFrame into the desired JSON format\n",
    "conversations = []\n",
    "for index, row in df.iterrows():\n",
    "    from_field = 'gpt' if 'Rick' in row['character'] else 'human'\n",
    "    conversation_entry = {\n",
    "        \"from\": from_field,\n",
    "        \"value\": row['dialogue']\n",
    "    }\n",
    "    conversations.append(conversation_entry)\n",
    "\n",
    "# Create the final JSON structure\n",
    "json_output = {\n",
    "    \"conversations\": conversations\n",
    "}\n",
    "\n",
    "# Save the JSON to a file\n",
    "output_file_path = 'RickDialogues.json'\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(json_output, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON file saved as {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dialogues saved to 'RickDialogues_modified_2.json'.\n"
     ]
    }
   ],
   "source": [
    "# Read the json file\n",
    "with open('RickDialogues.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Find the indices of GPT dialogues\n",
    "gpt_indices = [i for i, conv in enumerate(data[\"conversations\"]) if conv[\"from\"] == \"gpt\"]\n",
    "\n",
    "filtered_conversations = []  # Initialize list to store filtered conversations\n",
    "checked_indices = set()  # Keep track of checked human dialogues to maintain sequence\n",
    "\n",
    "for idx in gpt_indices:\n",
    "    filtered_conversations.append(data[\"conversations\"][idx])\n",
    "\n",
    "for i, conv in enumerate(data[\"conversations\"]):\n",
    "    if conv[\"from\"] == \"human\" and i not in checked_indices:\n",
    "        gpt_nearby = False\n",
    "        for j in range(max(0, i - 2), min(len(data[\"conversations\"]), i + 3)):\n",
    "            if j in gpt_indices:\n",
    "                gpt_nearby = True\n",
    "                break\n",
    "        if gpt_nearby:\n",
    "            filtered_conversations.append(conv)\n",
    "        checked_indices.add(i)\n",
    "\n",
    "# Sort the filtered conversations based on their original order\n",
    "filtered_conversations.sort(key=lambda x: data[\"conversations\"].index(x))\n",
    "\n",
    "# Save the filtered dialogues to a new json with correct sequence\n",
    "filtered_data = {\"conversations\": filtered_conversations}\n",
    "with open('RickDialogues_modified_2.json', 'w') as outfile:\n",
    "    json.dump(filtered_data, outfile, indent=4)\n",
    "\n",
    "print(\"Filtered dialogues saved to 'RickDialogues_modified_2.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved as RickDialogues_modified_2_part_1.json\n",
      "JSON file saved as RickDialogues_modified_2_part_2.json\n",
      "JSON file saved as RickDialogues_modified_2_part_3.json\n",
      "JSON file saved as RickDialogues_modified_2_part_4.json\n",
      "JSON file saved as RickDialogues_modified_2_part_5.json\n",
      "JSON file saved as RickDialogues_modified_2_part_6.json\n",
      "JSON file saved as RickDialogues_modified_2_part_7.json\n",
      "JSON file saved as RickDialogues_modified_2_part_8.json\n",
      "JSON file saved as RickDialogues_modified_2_part_9.json\n",
      "JSON file saved as RickDialogues_modified_2_part_10.json\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "input_file_path = 'RickDialogues_modified_2.json'\n",
    "with open(input_file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Get the conversations list\n",
    "conversations = data[\"conversations\"]\n",
    "\n",
    "# Calculate the number of conversations per file\n",
    "num_conversations = len(conversations)\n",
    "num_files = 10\n",
    "conversations_per_file = num_conversations // num_files\n",
    "remainder = num_conversations % num_files\n",
    "\n",
    "# Split the conversations into smaller files\n",
    "start_index = 0\n",
    "for i in range(num_files):\n",
    "    end_index = start_index + conversations_per_file + (1 if i < remainder else 0)\n",
    "    split_conversations = conversations[start_index:end_index]\n",
    "    \n",
    "    # Create the JSON structure for the split file\n",
    "    split_json_output = {\n",
    "        \"conversations\": split_conversations\n",
    "    }\n",
    "    \n",
    "    # Save the split JSON to a file\n",
    "    split_file_path = f'RickDialogues_modified_2_part_{i+1}.json'\n",
    "    with open(split_file_path, 'w') as split_json_file:\n",
    "        json.dump(split_json_output, split_json_file, indent=4)\n",
    "    \n",
    "    print(f\"JSON file saved as {split_file_path}\")\n",
    "    \n",
    "    start_index = end_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 472\n",
      "Number of dialogues per character:\n",
      "character\n",
      "Rick                   2916\n",
      "Morty                  1993\n",
      "jerry                   677\n",
      "summer                  580\n",
      "beth                    497\n",
      "                       ... \n",
      "villager 1                1\n",
      "owner                     1\n",
      "tickets please guy        1\n",
      "hamster news anchor       1\n",
      "beth and jerry            1\n",
      "Name: count, Length: 472, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Processed_RickandMortySeason1-7.csv'  # Update this with the correct path to your file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Normalize the character names\n",
    "data['character'] = data['character'].str.lower()\n",
    "data['character'] = data['character'].apply(lambda x: 'Rick' if 'rick' in x else ('Morty' if 'morty' in x else x))\n",
    "\n",
    "# Count the number of dialogues for each character\n",
    "character_dialogue_counts = data['character'].value_counts()\n",
    "\n",
    "# Count the number of unique characters\n",
    "unique_characters = data['character'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of unique characters: {unique_characters}\")\n",
    "print(\"Number of dialogues per character:\")\n",
    "print(character_dialogue_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
